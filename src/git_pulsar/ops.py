import logging
import os
import shutil
import subprocess
import sys
import textwrap
import time
from pathlib import Path

from rich.console import Console
from rich.panel import Panel

from . import system
from .constants import APP_NAME, BACKUP_NAMESPACE
from .git_wrapper import GitRepo

console = Console()
logger = logging.getLogger(APP_NAME)


def get_backup_ref(branch: str) -> str:
    """
    Constructs the fully qualified backup reference for the current machine and branch.

    Args:
        branch (str): The name of the branch to back up.

    Returns:
        str: The namespaced ref string (e.g., refs/heads/wip/pulsar/slug/branch).
    """
    slug = system.get_identity_slug()
    return f"refs/heads/{BACKUP_NAMESPACE}/{slug}/{branch}"


def bootstrap_env() -> None:
    """Bootstraps a Python development environment on macOS.

    This function scaffolds the environment using `uv` for package management,
    `direnv` for environment switching, and configures VS Code settings.

    Note:
        This workflow is currently optimized for macOS.
    """
    if sys.platform != "darwin":
        console.print(
            "[bold red]ERROR:[/bold red] The --env workflow is "
            "currently optimized for macOS."
        )
        return

    cwd = Path.cwd()
    console.print(
        f"[bold blue]SETUP:[/bold blue] Setting up dev environment in {cwd.name}..."
    )

    # 1. Dependency Check
    missing = []
    if not shutil.which("uv"):
        missing.append("uv")
    if not shutil.which("direnv"):
        missing.append("direnv")

    if missing:
        console.print(
            f"[bold red]ERROR:[/bold red] Missing tools: {', '.join(missing)}"
        )
        console.print("   Please run:")
        install_cmd = f"brew install {' '.join(missing)}"
        if not shutil.which("brew"):
            install_cmd = f"(Check your package manager) install {' '.join(missing)}"

        console.print(f"     {install_cmd}")
        sys.exit(1)

    # 2. Project Scaffold (uv)
    if not (cwd / "pyproject.toml").exists():
        console.print("[bold blue]INIT:[/bold blue] Initializing Python project...")
        # 'uv init' creates a standard pyproject.toml.
        subprocess.run(["uv", "init", "--no-workspace", "--python", "3.12"], check=True)
    else:
        console.print("   Existing pyproject.toml found. Skipping init.")

    # 3. Direnv Configuration
    envrc_path = cwd / ".envrc"
    if not envrc_path.exists():
        console.print("[bold blue]CONFIG:[/bold blue] Creating .envrc...")
        envrc_content = textwrap.dedent("""\
            # Auto-generated by git-pulsar
            if [ ! -d ".venv" ]; then
                echo "Creating virtual environment..."
                uv sync
            fi
            source .venv/bin/activate
            
            source_env_if_exists .envrc.local
        """)
        with open(envrc_path, "w") as f:
            f.write(envrc_content)

        subprocess.run(["direnv", "allow"], check=True)
    else:
        console.print("   .envrc exists. Skipping.")

    # 4. VS Code Settings
    vscode_dir = cwd / ".vscode"
    settings_path = vscode_dir / "settings.json"

    if not settings_path.exists():
        vscode_dir.mkdir(exist_ok=True)
        console.print("[bold blue]CONFIG:[/bold blue] Configuring VS Code...")
        settings_content = textwrap.dedent("""\
            {
                "python.defaultInterpreterPath": ".venv/bin/python",
                "python.terminal.activateEnvironment": true,
                "files.exclude": {
                    "**/__pycache__": true,
                    "**/.ipynb_checkpoints": true,
                    "**/.DS_Store": true,
                    "**/.venv": true
                },
                "search.exclude": {
                    "**/.venv": true
                }
            }
        """)
        with open(settings_path, "w") as f:
            f.write(settings_content)

    console.print("\n[bold green]SUCCESS:[/bold green] Environment ready.")

    if "DIRENV_DIR" not in os.environ:
        console.print("\n[bold yellow]ACTION REQUIRED:[/bold yellow] Enable direnv")
        console.print("   1. Open your config:")
        console.print("      code ~/.zshrc  (or nano ~/.zshrc)")
        console.print("   2. Add this line to the bottom:")
        console.print('      eval "$(direnv hook zsh)"')
        console.print("   3. Reload:")
        console.print("      source ~/.zshrc")


def restore_file(path_str: str, force: bool = False) -> None:
    """Restores a specific file from the latest backup of the current branch.

    Args:
        path_str (str): The relative path to the file to restore.
        force (bool): If True, overwrites uncommitted local changes. Defaults to False.
    """
    repo = GitRepo(Path.cwd())
    path = Path(path_str)

    current_branch = repo.current_branch()
    backup_ref = get_backup_ref(current_branch)

    # 1. Safety Check: Verify if the file is dirty.
    if not force and path.exists() and repo.status_porcelain(path_str):
        console.print(
            f"[bold red]ABORTED:[/bold red] '{path_str}' has uncommitted changes."
        )
        console.print("   Use --force to overwrite them.")
        sys.exit(1)

    # 2. Restore file from backup ref.
    console.print(
        f"[bold blue]RESTORING:[/bold blue] '{path_str}' from {backup_ref}..."
    )
    try:
        repo.checkout(backup_ref, file=path_str)
        console.print("[bold green]SUCCESS:[/bold green] Restore complete.")
    except Exception as e:
        logger.error(f"Failed to restore {path_str}: {e}")
        console.print(f"[bold red]ERROR:[/bold red] Failed to restore: {e}")
        sys.exit(1)


def sync_session() -> None:
    """Synchronizes the local workspace with the latest available backup session.

    This function scans backups from all machines for the current branch, identifies
    the most recent one, and (after confirmation) resets the local working directory
    to match it. This facilitates "Smart Handoff" between devices.
    """
    repo = GitRepo(Path.cwd())
    current_branch = repo.current_branch()

    # 1. Fetch backups from all sources.
    with console.status(
        f"[bold blue]Scanning for session on '{current_branch}'...[/bold blue]",
        spinner="dots",
    ):
        try:
            # Only fetch backups related to the current branch
            repo._run(
                [
                    "fetch",
                    "origin",
                    f"refs/heads/{BACKUP_NAMESPACE}/*/{current_branch}:refs/heads/{BACKUP_NAMESPACE}/*/{current_branch}",
                ],
                capture=True,
            )
        except Exception as e:
            logger.warning(f"Fetch error: {e}")
            console.print(
                "[yellow][bold]WARNING:[/bold] Fetch warning: network might be down "
                "(checking local cache).[/yellow]"
            )

    # 2. Find candidate refs (refs/heads/{namespace}/{machine}/{branch}).
    candidates = repo.list_refs(f"refs/heads/{BACKUP_NAMESPACE}/*/{current_branch}")

    if not candidates:
        console.print("[bold red]ERROR:[/bold red] No backups found anywhere.")
        return

    # 3. Sort candidates by commit timestamp (newest first).
    latest_ref = None
    latest_time = 0

    for ref in candidates:
        try:
            ts_str = repo._run(["log", "-1", "--format=%ct", ref])
            ts = int(ts_str.strip())
            if ts > latest_time:
                latest_time = ts
                latest_ref = ref
        except Exception:
            continue

    if not latest_ref:
        console.print("[bold red]ERROR:[/bold red] Could not determine latest backup.")
        return

    # 4. Compare with local state.
    machine_name = latest_ref.split("/")[-2]
    human_time = repo._run(["log", "-1", "--format=%cr", latest_ref])

    console.print(
        Panel(
            f"[bold]Source:[/bold] {machine_name}\n[bold]Time:[/bold]   {human_time}",
            title="Latest Session Found",
            border_style="green",
            expand=False,
        )
    )

    # Check if the local tree already matches the remote tree.
    local_tree = repo.write_tree()
    remote_tree = repo._run(["rev-parse", f"{latest_ref}^{{tree}}"])

    if local_tree == remote_tree:
        console.print("[bold green]SUCCESS:[/bold green] You are already up to date.")
        return

    # 5. Confirm overwrite.
    console.print(
        "\n[bold yellow]WARNING:[/bold yellow] This will overwrite your local "
        "changes to match the backup."
    )
    confirm = console.input("   Proceed with sync? [y/N] ").lower()
    if confirm != "y":
        console.print("[bold red]ABORTED.[/bold red]")
        sys.exit(0)

    # 6. Execute sync.
    try:
        # Checkout the contents of the backup ref to the worktree without moving HEAD.
        repo._run(["checkout", latest_ref, "--", "."])
        console.print(
            "[bold green]SUCCESS:[/bold green] Session synced. You may resume work."
        )
    except Exception as e:
        logger.warning(f"Sync failed: {e}")
        console.print(f"[bold red]ERROR:[/bold red] Sync failed: {e}")
        sys.exit(1)


def finalize_work() -> None:
    """Consolidates backup streams into the main branch.

    This performs an 'Octopus Squash' merge of all backup streams for the current
    branch into the main/master branch, effectively finalizing the work session
    and updating the primary project history.
    """
    console.print("[bold blue]FINALIZING:[/bold blue] Finalizing work...")
    repo = GitRepo(Path.cwd())

    # 1. Ensure working directory is clean.
    if repo.status_porcelain():
        console.print(
            "[bold yellow]WARNING:[/bold yellow] You have uncommitted changes."
        )
        console.print("   Please commit or stash them before finalizing.")
        sys.exit(1)

    working_branch = repo.current_branch()

    try:
        # 2. Sync with Remote.
        with console.status(
            "[bold blue]Syncing with origin...[/bold blue]", spinner="dots"
        ):
            try:
                repo._run(["fetch", "origin", "main"], capture=True)
                repo._run(
                    [
                        "fetch",
                        "origin",
                        f"refs/heads/{BACKUP_NAMESPACE}/*:refs/heads/{BACKUP_NAMESPACE}/*",
                    ],
                    capture=True,
                )
            except Exception as e:
                console.print(
                    f"[yellow][bold]WARNING:[/bold] Fetch warning: {e}[/yellow]"
                )

        # 3. Identify Backup Candidates for the current branch.
        candidates = repo.list_refs(f"refs/heads/{BACKUP_NAMESPACE}/*/{working_branch}")

        if not candidates:
            console.print(
                "[bold red]ERROR:[/bold red] No backups found for this branch."
            )
            sys.exit(1)

        console.print(f"-> Found {len(candidates)} backup stream(s):")
        for c in candidates:
            console.print(f"   â€¢ {c}")

        # 4. Switch to the target branch (main/master).
        target = "main"
        if not repo.rev_parse("main") and repo.rev_parse("master"):
            target = "master"

        console.print(f"-> Switching to {target}...")
        repo.checkout(target)

        # 5. Perform Octopus Squash Merge.
        with console.status(
            f"[bold blue]Collapsing {len(candidates)} backup streams...[/bold blue]",
            spinner="dots",
        ):
            try:
                repo.merge_squash(*candidates)
            except RuntimeError:
                console.print(
                    "[bold red]CONFLICT:[/bold red] Merge conflicts detected. "
                    "Please resolve them, then commit."
                )
                sys.exit(0)

        # 6. Interactive Commit.
        console.print("-> Committing (opens editor)...")
        repo.commit_interactive()

        console.print("\n[bold green]SUCCESS:[/bold green] Work finalized!")
        console.print(f"   Your backup history remains in refs/{BACKUP_NAMESPACE}/...")

    except Exception as e:
        logger.error(f"Finalize failed: {e}")
        console.print(f"\n[bold red]ERROR:[/bold red] Error during finalize: {e}")
        sys.exit(1)


def prune_backups(days: int, repo_path: Path | None = None) -> None:
    """Garbage collects backup references older than the specified retention period.

    Args:
        days (int): The retention period in days.
        repo_path (Path | None, optional): The path to the repository. Defaults to CWD.
    """
    repo = GitRepo(repo_path or Path.cwd())
    cutoff = time.time() - (days * 86400)

    console.print(
        f"[bold blue]MAINTENANCE:[/bold blue] "
        f"Scanning for backups older than {days} days..."
    )

    refs = repo.list_refs(f"refs/heads/{BACKUP_NAMESPACE}/")
    deleted_count = 0

    for ref in refs:
        try:
            ts_str = repo._run(["log", "-1", "--format=%ct", ref])
            ts = int(ts_str.strip())

            if ts < cutoff:
                age_days = (time.time() - ts) / 86400
                console.print(f"   Deleting {ref} (Age: {age_days:.1f} days)")
                repo._run(["update-ref", "-d", ref], capture=False)
                deleted_count += 1
        except Exception:
            continue

    if deleted_count == 0:
        console.print("[dim]No stale backups found.[/dim]")
    else:
        console.print(f"[bold red]Dropped {deleted_count} stale refs.[/bold red]")
        with console.status(
            "[bold blue]Running garbage collection (git gc)...[/bold blue]",
            spinner="dots",
        ):
            repo._run(["gc", "--auto"], capture=True)


def add_ignore(pattern: str) -> None:
    """Adds a file pattern to .gitignore and removes matching files from the index.

    If files matching the pattern are currently tracked, the user is prompted to
    stop tracking them (while keeping the files on disk).

    Args:
        pattern (str): The file pattern to ignore (e.g., '*.log').
    """
    cwd = Path.cwd()
    gitignore = cwd / ".gitignore"

    # 1. Append to .gitignore if not present.
    content = ""
    if gitignore.exists():
        with open(gitignore) as f:
            content = f.read()

    if pattern in content:
        console.print(f"[blue]INFO:[/blue] '{pattern}' is already in .gitignore.")
    else:
        with open(gitignore, "a") as f:
            prefix = "\n" if content and not content.endswith("\n") else ""
            f.write(f"{prefix}{pattern}\n")
        console.print(
            f"[bold green]SUCCESS:[/bold green] Added '{pattern}' to .gitignore."
        )

    # 2. Check if currently tracked and offer to remove from index.
    repo = GitRepo(cwd)
    try:
        tracked = repo._run(["ls-files", pattern])
        if tracked:
            console.print(
                f"[bold yellow]WARNING:[/bold yellow] "
                f"Files matching '{pattern}' are currently tracked by git."
            )
            confirm = console.input(
                "   Stop tracking them (keep local file)? [y/N] "
            ).lower()
            if confirm == "y":
                repo._run(["rm", "--cached", pattern], capture=False)
                console.print("   Removed from index (file preserved on disk).")
    except Exception as e:
        logger.warning(f"Failed to remove tracked files: {e}")
        pass
